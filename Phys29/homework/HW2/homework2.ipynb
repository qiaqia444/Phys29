{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Qia Wang HW2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"font-size: 32px; text-align: center;\">Introduction to Computer Programming for the Physical Sciences</h1>\n",
    "<h2 style=\"font-size: 24px; text-align: center;\">Joseph F. Hennawi</h2>\n",
    "<h3 style=\"font-size: 24px; text-align: center;\">Winter 2024</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ul style=\"list-style: none;\">\n",
    "  <li style=\"margin-bottom: 10px; font-size: 20px;\"><span style=\"display: inline-block; width: 10px; height: 10px; border: 2px solid black; margin-right: 10px;\"></span>Open a new Jupyter notebook</li>\n",
    "  <li style=\"margin-bottom: 10px; font-size: 20px;\"><span style=\"display: inline-block; width: 10px; height: 10px; border: 2px solid black; margin-right: 10px;\"></span>Name your notebook with your name and Homework 1</li>\n",
    "  <li style=\"margin-bottom: 10px; font-size: 20px;\"><span style=\"display: inline-block; width: 10px; height: 10px; border: 2px solid black; margin-right: 10px;\"></span>Open a Markdown cell at the top and write your name and Homework 1</li>\n",
    "  <li style=\"margin-bottom: 10px; font-size: 20px;\"><span style=\"display: inline-block; width: 10px; height: 10px; border: 2px solid black; margin-right: 10px;\"></span>Open a Markdown cell before each problem and write e.g. Problem 1, Problem 2(a), etc.</li>\n",
    "  <li style=\"margin-bottom: 10px; font-size: 20px;\"><span style=\"display: inline-block; width: 10px; height: 10px; border: 2px solid black; margin-right: 10px;\"></span>Please abide by the <b><a href=\"https://github.com/enigma-igm/Phys29/blob/main/using_AI_tools.md\">Policy and Guidelines on Using AI Tools</a></b></li>\n",
    "  <li style=\"margin-bottom: 10px; font-size: 20px;\"><span style=\"display: inline-block; width: 10px; height: 10px; border: 2px solid black; margin-right: 10px;\"></span>Once you finish the problems: 1) Restart the Python kernel and clear all cell outputs. 2) Rerun the notebook from start to finish so that all answers/outputs show up. 3) Save your notebook as a single .pdf file and upload it to Gradescope on Canvas by the deadline. <b>No late homeworks will be accepted except for illness accompanied by a doctor's note.</b></li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 2\n",
    "\n",
    "## Problem 1: Range of a Projectile\n",
    "Write a Python function that computes the range of a projectile that is launched from height $y_0$ above the ground at speed $v_0$ at angle $\\alpha$ above the horizontal direction.  By *range*, I mean the horizontal distance traveled before reaching the ground.  Neglect air resistance and Coriolis effects.  For $y_0=11~{\\rm m}$ and $v_0=13~{\\rm m~s^{-1}}$, which of the following angles gives the biggest range: $\\alpha=20^\\circ, 30^\\circ, 40^\\circ, 50^\\circ, 60^\\circ$?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The angle that gives the biggest range is 30 degrees.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "# a function takes in height, velocity, and angle of projectile and returns the range\n",
    "def range_projectile(y0,v0,alpha):\n",
    "    g = 9.81\n",
    "    radians = alpha * (np.pi / 180)\n",
    "    # total time in the air, only y-component matters here\n",
    "    t = (np.sqrt((v0 * np.sin(radians)) ** 2 + 2 * g * y0) + v0 * (np.sin(radians)))/g\n",
    "    # range = vx * t\n",
    "    range = np.cos(radians) * v0 * t\n",
    "    return range\n",
    "\n",
    "\n",
    "# Initial conditions\n",
    "y0 = 11  \n",
    "v0 = 13  \n",
    "angles = [20, 30, 40, 50, 60]  # degrees\n",
    "\n",
    "# Calculate the range for each angle and find the angle that gives the biggest range\n",
    "max_range = 0\n",
    "best_angle = 0\n",
    "for alpha in angles: # run through all angles and find the angle with biggest range\n",
    "    range = range_projectile(y0, v0, alpha)\n",
    "    if range > max_range:\n",
    "        max_range = range\n",
    "        best_angle = alpha\n",
    "\n",
    "print(f\"The angle that gives the biggest range is {best_angle} degrees.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 2: Fun with Conditional Statments\n",
    "Using ${\\tt if}, {\\tt elif}, {\\tt else}$ statements, write a Python function that takes any three distinct real input numbers $a$, $b$, and $c$, and returns the same values in a tuple in order of smallest to largest. For example, if $a=3$, $b=1$, and $c=2$, then the function should return the tuple $(1,2,3)$.  If $a=3$, $b=2$, and $c=3$, then the function should return the tuple $(2,3,3)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 2, 3)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# a function that takes three numbers as arguments and returns them in sorted order\n",
    "def small_to_large(a, b, c):\n",
    "    if a >= b: # compare first two numbers\n",
    "        if a >= c: # a & c are largest\n",
    "            if b >= c: # conpare last two numbers\n",
    "                return c,b,a\n",
    "            else:\n",
    "                return b,c,a\n",
    "        else:\n",
    "            return b,a,c\n",
    "    if a < b: # compare first two numbers\n",
    "        if b >= c: # b & c are largest\n",
    "            if a < c: # conpare first and last numbers\n",
    "                return a,c,b\n",
    "            else:\n",
    "                return c,a,b\n",
    "        else:\n",
    "            return a,b,c\n",
    "small_to_large(1, 2, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 3: Machine Epsilon\n",
    "In the lecture we discussed the limited precision of floating point numbers and floating point arithmetic. An important value to quantity is floating-point accuracy which is referred to as the *machine epsilon*. Please read this [Wikipedia article on the machine epsilon](https://en.wikipedia.org/wiki/Machine_epsilon) to learn more about this important concept. \n",
    "\n",
    "The machine epsilon is defined as the smallest number $\\epsilon_m$ such that $1 + \\epsilon_m > 1$. According to the Wikipedia article, the machine epsilon in python can be estimated to within a factor of two via the algorithm:\n",
    "```python\n",
    "epsilon_m = 1.0\n",
    "while (1.0 + 0.5*epsilon_m) != 1.0:\n",
    "    epsilon_m /= 2.0\n",
    "```\n",
    "\n",
    "**a)** Write a python function that implements this algorithm and returns the machine epsilon. Which float-type is used in Python (see the table of the Wikipedia article)?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**b)** In lecture it was argued that in Python the smallest number that can be represented in python is about `1e-308`, which is many orders of magnitude smaller than the \\( $\\epsilon_m$ \\) that you just derived. What is the difference between the smallest representable floating point number and the machine epsilon?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**c)** Consider 32bit floating point numbers, or so called single-precision. To within an order of magnitude estimate the machine epsilon, the smallest number that can be represented, and the largest number that can be represented. Repeat your estimates for 16bit floating point numbers. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.220446049250313e-16\n"
     ]
    }
   ],
   "source": [
    "# a)\n",
    "def return_machine_epsilon():\n",
    "    epsilon_m = 1.0\n",
    "    while (1.0 + 0.5 * epsilon_m) != 1.0:\n",
    "        epsilon_m = epsilon_m / 2.0\n",
    "    return epsilon_m\n",
    "print(return_machine_epsilon())\n",
    "# 2.220446049250313e-16\n",
    "\n",
    "# b)\n",
    "# 1e-308 represents the smallest positive value that can be stored in a Python float\n",
    "# machine epsilon is the difference between 1.0 and the next representable floating-point number that is greater than 1.0 in this case.\n",
    "\n",
    "# c)\n",
    "# for 32 bit float point numbers.\n",
    "# largest number: 2 ** 127 * (2 - 2^-23)\n",
    "# smallest number: 2 ** -126 * (1 + 2^-23)\n",
    "# machine epsilon: 2 ** -23\n",
    "\n",
    "# for 8 bit float point numbers.\n",
    "# largest number: 2 ** 7 * (2 - 2^-3)\n",
    "# smallest number: 2 ** -6 * (1 + 2^-3)\n",
    "# machine epsilon: 2 ** -3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 4: Numerical Derivatives\n",
    "In this problem we will explore the accuracy of numerical derivatives. Consider the function $f(x) = x^2(x-1)$\n",
    "\n",
    "**a)** Analytically compute $f^\\prime(x)$ and evauate it at $x=1.0$.\n",
    "\n",
    "**b)** Write a python function that estimates the derivative of $f(x)$ numerically using the forward difference formula:\n",
    "$$\n",
    "f^\\prime(x) \\approx \\frac{f(x+h) - f(x)}{h}\n",
    "$$\n",
    "where $h$ is a small number.\n",
    "**c)** Write another python function that estimates the derivative of $f(x)$ numerically using the symmetric difference formula:\n",
    "$$\n",
    "f^\\prime(x) \\approx \\frac{f(x+h) - f(x-h)}{2h}\n",
    "$$\n",
    "**d)** Calculate $f^\\prime(1.0)$ using your two numerical derivative functions for $h=10^{-1}, 10^{-2}, 10^{-3}, 10^{-4}, ....$ until something *really bad happens* (see below). Print out both $h$ and $f^\\prime(1.0)$, as $h$ becomes smaller and smaller. Format the output of $f^\\prime(1.0)$ to show 16 digits after the decimal point. Do the calculation using the built-in python float data type (nothing fancy please!)\n",
    "\n",
    "**e)** Based on your outputs from above, you should see that the symmetric difference formula is always more precise at a given value of $h$. To understand why this is the case we need a bit of calculcus. The Taylor expansion of $f(x)$ around $x$ is given by:\n",
    "$$\n",
    "f(x+h) = f(x) + h f^\\prime(x) + \\frac{h^2}{2} f^{\\prime\\prime}(x) + \\frac{h^3}{3!} f^{\\prime\\prime\\prime}(x) + \\frac{h^4}{4!} f^{\\prime\\prime\\prime\\prime}(x) + \\cdots\n",
    "$$\n",
    "which states that for small values of $h$, the function can be expanded as a sum of powers of $h$ and higher order derivatives of $f(x)$. \n",
    "\n",
    "Derive expressions for $f^\\prime(x)$ using the Taylor expansion above for the two numerical derivative formulas that we employed in part (b) and (c).\n",
    "\n",
    "**f)** Based on your answers to part (e), explain why the symmetric difference formula is always more precise than the forward difference formula in the limit $h\\rightarrow 0$. Note that the amount of computational work for both of the derivative estimators is the same, i.e. the function is evaluated at two locations, and then division by $h$ or $2h$ is performed. Hence, this problem illustrates that numerical derivatives should always be calculated  using symmetric differences whenever possible. \n",
    "\n",
    "**g)** As $h$ becomes *too small* the precision of both of the derivative estimators starts to degrade. This is because when $h$ is extremely small, taking the difference of $f(x+h)$ and $f(x - h)$ (or $f(x+h)$ and $f(x)$) becomes problematic as you are subtracting two numbers that are very close to each other. Read this Wikipedia article on [catastrophic cancellation](https://en.wikipedia.org/wiki/Catastrophic_cancellation) and describe in your own words why the numerical preision degrades when $h$ becomes too small.\n",
    "\n",
    "It can be shown that catastrophic cancellation starts to degrade results when $h\\approx x\\sqrt{\\epsilon_m}$ (forward difference estimator) or \n",
    "$h\\approx x\\epsilon_m^{2/3}$ (symmetric difference estimator), where $\\epsilon_m\\simeq 2\\times 10^{-16}$ is the machine epsilon that we derived in Problem 3. These formulas are reliable provided that $x$ is not too close to zero (in our problem $x=1$ so we are okay). For more background on where these scalings come from see Chapter 5.7 of [Numerical Recipes](http://tinyurl.com/yc36ac7z)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h=0.1000000000000000, forward difference=1.2100000000000022, central difference=1.0100000000000009\n",
      "h=0.0100000000000000, forward difference=1.0201000000000124, central difference=1.0001000000000035\n",
      "h=0.0010000000000000, forward difference=1.0020010000000299, central difference=1.0000010000000279\n",
      "h=0.0001000000000000, forward difference=1.0002000099995632, central difference=1.0000000100002235\n",
      "h=0.0000100000000000, forward difference=1.0000200000970234, central difference=1.0000000000953686\n",
      "h=0.0000010000000000, forward difference=1.0000019998734895, central difference=0.9999999999177330\n",
      "h=0.0000001000000000, forward difference=1.0000002004240112, central difference=1.0000000000287552\n",
      "h=0.0000000100000000, forward difference=1.0000000161269891, central difference=0.9999999994736436\n",
      "h=0.0000000010000000, forward difference=1.0000000827403706, central difference=1.0000000272292193\n",
      "h=0.0000000001000000, forward difference=1.0000000827403706, central difference=1.0000000827403706\n",
      "h=0.0000000000100000, forward difference=1.0000000827403703, central difference=1.0000000827403703\n",
      "h=0.0000000000010000, forward difference=1.0000889005823403, central difference=1.0000333894311091\n",
      "h=0.0000000000001000, forward difference=0.9992007221626402, central difference=0.9997558336749528\n",
      "h=0.0000000000000100, forward difference=0.9992007221626401, central difference=0.9992007221626401\n",
      "h=0.0000000000000010, forward difference=1.1102230246251557, central difference=1.0547118733938978\n",
      "h=0.0000000000000001, forward difference=0.0000000000000000, central difference=0.5551115123125777\n",
      "h=0.0000000000000000, forward difference=0.0000000000000000, central difference=0.0000000000000000\n",
      "h=0.0000000000000000, forward difference=0.0000000000000000, central difference=0.0000000000000000\n",
      "h=0.0000000000000000, forward difference=0.0000000000000000, central difference=0.0000000000000000\n",
      "h=0.0000000000000000, forward difference=0.0000000000000000, central difference=0.0000000000000000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nh=0.1000000000000000, forward difference=1.2100000000000011, central difference=1.0100000000000005\\nh=0.0100000000000000, forward difference=1.0201000000000007, central difference=1.0001000000000007\\nh=0.0010000000000000, forward difference=1.0020009999998891, central difference=1.0000009999999451\\nh=0.0001000000000000, forward difference=1.0002000099998893, central difference=1.0000000099998896\\nh=0.0000100000000000, forward difference=1.0000200001065511, central difference=1.0000000001009999\\nh=0.0000010000000000, forward difference=1.0000019999187328, central difference=0.9999999999742440\\nh=0.0000001000000000, forward difference=1.0000002005838768, central difference=1.0000000000287654\\nh=0.0000000100000000, forward difference=1.0000000139225282, central difference=0.9999999994736433\\nh=0.0000000010000000, forward difference=1.0000000847403707, central difference=1.0000000272292195\\nh=0.0000000001000000, forward difference=1.0000000829403703, central difference=1.0000000827403706\\nh=0.0000000000100000, forward difference=1.0000000827603703, central difference=1.0000000827403703\\nh=0.0000000000010000, forward difference=1.0000889005843407, central difference=1.0000333894311093\\nh=0.0000000000001000, forward difference=0.9992007221628399, central difference=0.9997558336749526\\nh=0.0000000000000100, forward difference=0.9992007221626601, central difference=0.9992007221626401\\nh=0.0000000000000010, forward difference=1.1102230246251579, central difference=1.0547118733938980\\nh=0.0000000000000001, forward difference=0.0000000000000000, central difference=0.5551115123125776\\nh=0.0000000000000000, forward difference=0.0000000000000000, central difference=0.0000000000000000\\nh=0.0000000000000000, forward difference=0.0000000000000000, central difference=0.0000000000000000\\nh=0.0000000000000000, forward difference=0.0000000000000000, central difference=0.0000000000000000\\nh=0.0000000000000000, forward difference=0.0000000000000000, central difference=0.0000000000000000\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# a)\n",
    "f = lambda x: x ** 3 - x ** 2\n",
    "# f'(x) = 3x ^ 2 - 2x\n",
    "# f'(1) = 1\n",
    "\n",
    "# b)\n",
    "def derivative_forward_difference(f, x, h):\n",
    "    return (f(x + h) - f(x)) / h\n",
    "\n",
    "def derivative_symmetric_difference(f ,x, h):\n",
    "    return (f(x + h) - f(x - h)) / (2 * h)\n",
    "\n",
    "# d)\n",
    "h = 0.1\n",
    "# h changes by a factor of 0.1 each time until it is smaller than 1e-20\n",
    "while h > 1e-20:\n",
    "    fd = derivative_forward_difference(f, 1.0, h)\n",
    "    cd = derivative_symmetric_difference(f, 1.0, h)\n",
    "    print(f\"h={h:.16f}, forward difference={fd:.16f}, central difference={cd:.16f}\")\n",
    "    h *= 0.1\n",
    "# ArithmeticError: integer division or modulo by zero\n",
    "# when h is too small, the computer cannot represent the number accurately, thus the error occurs.\n",
    "'''\n",
    "h=0.1000000000000000, forward difference=1.2100000000000011, central difference=1.0100000000000005\n",
    "h=0.0100000000000000, forward difference=1.0201000000000007, central difference=1.0001000000000007\n",
    "h=0.0010000000000000, forward difference=1.0020009999998891, central difference=1.0000009999999451\n",
    "h=0.0001000000000000, forward difference=1.0002000099998893, central difference=1.0000000099998896\n",
    "h=0.0000100000000000, forward difference=1.0000200001065511, central difference=1.0000000001009999\n",
    "h=0.0000010000000000, forward difference=1.0000019999187328, central difference=0.9999999999742440\n",
    "h=0.0000001000000000, forward difference=1.0000002005838768, central difference=1.0000000000287654\n",
    "h=0.0000000100000000, forward difference=1.0000000139225282, central difference=0.9999999994736433\n",
    "h=0.0000000010000000, forward difference=1.0000000847403707, central difference=1.0000000272292195\n",
    "h=0.0000000001000000, forward difference=1.0000000829403703, central difference=1.0000000827403706\n",
    "h=0.0000000000100000, forward difference=1.0000000827603703, central difference=1.0000000827403703\n",
    "h=0.0000000000010000, forward difference=1.0000889005843407, central difference=1.0000333894311093\n",
    "h=0.0000000000001000, forward difference=0.9992007221628399, central difference=0.9997558336749526\n",
    "h=0.0000000000000100, forward difference=0.9992007221626601, central difference=0.9992007221626401\n",
    "h=0.0000000000000010, forward difference=1.1102230246251579, central difference=1.0547118733938980\n",
    "h=0.0000000000000001, forward difference=0.0000000000000000, central difference=0.5551115123125776\n",
    "h=0.0000000000000000, forward difference=0.0000000000000000, central difference=0.0000000000000000\n",
    "h=0.0000000000000000, forward difference=0.0000000000000000, central difference=0.0000000000000000\n",
    "h=0.0000000000000000, forward difference=0.0000000000000000, central difference=0.0000000000000000\n",
    "h=0.0000000000000000, forward difference=0.0000000000000000, central difference=0.0000000000000000\n",
    "'''\n",
    "\n",
    "# e)\n",
    "# O() is the order of the error term. that is not inportant here for it is small enough to be ignored.\n",
    "# Forward differenece \n",
    "# f(x+h) = f(x) + h * f'(x) + (h^2 / 2！) * f''(x）+ O(h^3）\n",
    "# f'(x) = (f(x+h) - f(x)) / h - (h / 2!) * f''(x) + O(h^2)\n",
    "\n",
    "# Central differenece\n",
    "# f(x+h) = f(x) + h * f'(x) + (h^2 / 2！) * f''(x）+ (h^3 / 3!) * f'''(x) + O(h^4）\n",
    "# f(x-h) = f(x) - h * f'(x) + (h^2 / 2！) * f''(x）- (h^3 / 3!) * f'''(x) + O(h^4）\n",
    "# f'(x) = (f(x+h) - f(x-h)) / 2h - (h^2 / 3!) * f'''(x) + O(h^4)\n",
    "\n",
    "# f)\n",
    "# Forward differenece \n",
    "# (h / 2!) * f''(x) is the error term\n",
    "# The forward difference formula approximates the derivative at a point by considering the slope of the line through that point and a point h units forward. \n",
    "\n",
    "# Central differenece\n",
    "# (h^2 / 3!) * f'''(x) is the error term\n",
    "# The symmetric difference formula, on the other hand, approximates the derivative at a point by considering the slope of the line through a point h units \n",
    "# backward and a point h units forward.\n",
    "\n",
    "# thus central difference is more accurate than forward difference\n",
    "\n",
    "# g)\n",
    "# when h becomes to small, the issue aries sue to the finit precision of the computer with floating point numbers. when two nearly equal numbers\n",
    "# are subtracted, many significant digits are lost."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
